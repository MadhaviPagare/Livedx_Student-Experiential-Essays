{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b6de39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, TFRobertaModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e469d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on GPU: 1\n"
     ]
    }
   ],
   "source": [
    "# Set up the TPU or GPU strategy\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "    print('Running on TPU:', tpu.master())\n",
    "except ValueError:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "    print('Running on GPU:', strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15b40d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "MODEL_NAME = 'roberta-base'\n",
    "MAX_LEN = 256\n",
    "BATCH_SIZE = 8 * strategy.num_replicas_in_sync\n",
    "EPOCHS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4543d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "df = pd.read_csv('C:/Users/.......  /.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4766b85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Text', 'Task1', 'Task2', 'Task3', 'Task4', 'Task5', 'Task6', 'Task7', 'Task8', 'Task9', 'Task10', 'Task11', 'Task12', 'Task13', 'Task14', 'Task15']\n"
     ]
    }
   ],
   "source": [
    "columns = df.columns.tolist()\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ba214d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Task1</th>\n",
       "      <th>Task2</th>\n",
       "      <th>Task3</th>\n",
       "      <th>Task4</th>\n",
       "      <th>Task5</th>\n",
       "      <th>Task6</th>\n",
       "      <th>Task7</th>\n",
       "      <th>Task8</th>\n",
       "      <th>Task9</th>\n",
       "      <th>Task10</th>\n",
       "      <th>Task11</th>\n",
       "      <th>Task12</th>\n",
       "      <th>Task13</th>\n",
       "      <th>Task14</th>\n",
       "      <th>Task15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didn't spend all my money buying squishmallo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It was a busy day at work and as I was quite b...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ive been reading a book that helped answer a l...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I worked out. tough. worked out. working out i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The situation was not that easy to handle, but...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Task1  Task2  Task3  \\\n",
       "0  i didn't spend all my money buying squishmallo...      0      0      0   \n",
       "1  It was a busy day at work and as I was quite b...      0      1      0   \n",
       "2  Ive been reading a book that helped answer a l...      1      0      0   \n",
       "3  I worked out. tough. worked out. working out i...      0      0      0   \n",
       "4  The situation was not that easy to handle, but...      0      0      1   \n",
       "\n",
       "   Task4  Task5  Task6  Task7  Task8  Task9  Task10  Task11  Task12  Task13  \\\n",
       "0      1      0      0      0      0      0       1       0       0       0   \n",
       "1      0      0      0      0      0      0       1       0       0       0   \n",
       "2      0      0      0      0      0      0       1       0       0       0   \n",
       "3      0      0      0      0      0      0       0       1       0       0   \n",
       "4      0      0      0      0      0      0       0       0       0       0   \n",
       "\n",
       "   Task14  Task15  \n",
       "0       1       1  \n",
       "1       0       1  \n",
       "2       0       1  \n",
       "3       1       1  \n",
       "4       1       1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb0b1054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into X_data (text) and task labels (Task1 to Task14)\n",
    "X_data = df['Text'].values\n",
    "task_labels = df.iloc[:, 1:14].values.astype('int32')\n",
    "presence_labels = df['Task15'].values.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a37d5bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'task_labels' is a NumPy ndarray containing the task labels\n",
    "task_labels_sum = np.sum(task_labels[:, :13], axis=0)\n",
    "task_names = ['Task' + str(i) for i in range(1, 14)]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(task_names, task_labels_sum, align='center', alpha=0.5)\n",
    "plt.ylabel('Number of instances')\n",
    "plt.title('Distribution of instances per task')\n",
    "plt.gca().yaxis.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf574e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train_task, y_test_task, y_train_presence, y_test_presence = train_test_split(\n",
    "    X_data, task_labels, presence_labels, test_size=0.3, random_state=777)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0527429c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Roberta tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed3b8e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the text data using the tokenizer\n",
    "def roberta_encode(texts, tokenizer):\n",
    "    input_ids = np.ones((len(texts), MAX_LEN), dtype='int32')\n",
    "    attention_mask = np.zeros((len(texts), MAX_LEN), dtype='int32')\n",
    "\n",
    "    for i, text in enumerate(texts):\n",
    "        tokens = tokenizer.tokenize(text)\n",
    "        tokens = tokens[:MAX_LEN-2]\n",
    "        tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
    "        input_ids[i, :len(tokens)] = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        attention_mask[i, :len(tokens)] = 1\n",
    "\n",
    "    return {\n",
    "        'input_word_ids': input_ids,\n",
    "        'input_mask': attention_mask\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e1e45dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the train and test data\n",
    "X_train_encoded = roberta_encode(X_train, tokenizer)\n",
    "X_test_encoded = roberta_encode(X_test, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "635f4a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Multitask Cascaded Roberta model\n",
    "def build_model():\n",
    "    with strategy.scope():\n",
    "        input_word_ids = tf.keras.Input(shape=(MAX_LEN,), dtype=tf.int32, name='input_word_ids')\n",
    "        input_mask = tf.keras.Input(shape=(MAX_LEN,), dtype=tf.int32, name='input_mask')\n",
    "\n",
    "        roberta = TFRobertaModel.from_pretrained(MODEL_NAME)\n",
    "        roberta.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "        sequence_output = roberta(input_word_ids, attention_mask=input_mask)[0]\n",
    "        cls_token = sequence_output[:, 0, :]\n",
    "\n",
    "        presence_output = tf.keras.layers.Dense(1, activation='sigmoid', name='presence_output')(cls_token)\n",
    "        task_output = tf.keras.layers.Dense(13, activation='sigmoid', name='task_output')(cls_token)\n",
    "\n",
    "        task_loss = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "        presence_loss = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "        task_metrics = [tf.keras.metrics.BinaryAccuracy(name='task{}_accuracy'.format(i+1)) for i in range(13)]\n",
    "        presence_metrics = tf.keras.metrics.BinaryAccuracy(name='presence_accuracy')\n",
    "\n",
    "        model = tf.keras.Model(inputs=[input_word_ids, input_mask], outputs=[task_output, presence_output])\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "                      loss={'task_output': task_loss, 'presence_output': presence_loss},\n",
    "                      metrics={'task_output': task_metrics, 'presence_output': presence_metrics})\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0a3304a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_word_ids (InputLayer)    [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " input_mask (InputLayer)        [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " tf_roberta_model (TFRobertaMod  TFBaseModelOutputWi  124645632  ['input_word_ids[0][0]',         \n",
      " el)                            thPoolingAndCrossAt               'input_mask[0][0]']             \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 256,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_roberta_model[0][0]']       \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " task_output (Dense)            (None, 13)           9997        ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " presence_output (Dense)        (None, 1)            769         ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 124,656,398\n",
      "Trainable params: 124,656,398\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build and compile the model\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c219a23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "131/131 [==============================] - 1578s 12s/step - loss: 0.5661 - task_output_loss: 0.3097 - presence_output_loss: 0.2565 - task_output_task1_accuracy: 0.8878 - task_output_task2_accuracy: 0.8878 - task_output_task3_accuracy: 0.8878 - task_output_task4_accuracy: 0.8878 - task_output_task5_accuracy: 0.8878 - task_output_task6_accuracy: 0.8878 - task_output_task7_accuracy: 0.8878 - task_output_task8_accuracy: 0.8878 - task_output_task9_accuracy: 0.8878 - task_output_task10_accuracy: 0.8878 - task_output_task11_accuracy: 0.8878 - task_output_task12_accuracy: 0.8878 - task_output_task13_accuracy: 0.8878 - presence_output_presence_accuracy: 0.9294 - val_loss: 0.4283 - val_task_output_loss: 0.2325 - val_presence_output_loss: 0.1958 - val_task_output_task1_accuracy: 0.9274 - val_task_output_task2_accuracy: 0.9274 - val_task_output_task3_accuracy: 0.9274 - val_task_output_task4_accuracy: 0.9274 - val_task_output_task5_accuracy: 0.9274 - val_task_output_task6_accuracy: 0.9274 - val_task_output_task7_accuracy: 0.9274 - val_task_output_task8_accuracy: 0.9274 - val_task_output_task9_accuracy: 0.9274 - val_task_output_task10_accuracy: 0.9274 - val_task_output_task11_accuracy: 0.9274 - val_task_output_task12_accuracy: 0.9274 - val_task_output_task13_accuracy: 0.9274 - val_presence_output_presence_accuracy: 0.9422\n",
      "Epoch 2/3\n",
      "131/131 [==============================] - 1458s 11s/step - loss: 0.4359 - task_output_loss: 0.2222 - presence_output_loss: 0.2137 - task_output_task1_accuracy: 0.9315 - task_output_task2_accuracy: 0.9315 - task_output_task3_accuracy: 0.9315 - task_output_task4_accuracy: 0.9315 - task_output_task5_accuracy: 0.9315 - task_output_task6_accuracy: 0.9315 - task_output_task7_accuracy: 0.9315 - task_output_task8_accuracy: 0.9315 - task_output_task9_accuracy: 0.9315 - task_output_task10_accuracy: 0.9315 - task_output_task11_accuracy: 0.9315 - task_output_task12_accuracy: 0.9315 - task_output_task13_accuracy: 0.9315 - presence_output_presence_accuracy: 0.9437 - val_loss: 0.4106 - val_task_output_loss: 0.2188 - val_presence_output_loss: 0.1917 - val_task_output_task1_accuracy: 0.9274 - val_task_output_task2_accuracy: 0.9274 - val_task_output_task3_accuracy: 0.9274 - val_task_output_task4_accuracy: 0.9274 - val_task_output_task5_accuracy: 0.9274 - val_task_output_task6_accuracy: 0.9274 - val_task_output_task7_accuracy: 0.9274 - val_task_output_task8_accuracy: 0.9274 - val_task_output_task9_accuracy: 0.9274 - val_task_output_task10_accuracy: 0.9274 - val_task_output_task11_accuracy: 0.9274 - val_task_output_task12_accuracy: 0.9274 - val_task_output_task13_accuracy: 0.9274 - val_presence_output_presence_accuracy: 0.9422\n",
      "Epoch 3/3\n",
      "131/131 [==============================] - 1569s 12s/step - loss: 0.4027 - task_output_loss: 0.2068 - presence_output_loss: 0.1959 - task_output_task1_accuracy: 0.9330 - task_output_task2_accuracy: 0.9330 - task_output_task3_accuracy: 0.9330 - task_output_task4_accuracy: 0.9330 - task_output_task5_accuracy: 0.9330 - task_output_task6_accuracy: 0.9330 - task_output_task7_accuracy: 0.9330 - task_output_task8_accuracy: 0.9330 - task_output_task9_accuracy: 0.9330 - task_output_task10_accuracy: 0.9330 - task_output_task11_accuracy: 0.9330 - task_output_task12_accuracy: 0.9330 - task_output_task13_accuracy: 0.9330 - presence_output_presence_accuracy: 0.9408 - val_loss: 0.4072 - val_task_output_loss: 0.2118 - val_presence_output_loss: 0.1953 - val_task_output_task1_accuracy: 0.9282 - val_task_output_task2_accuracy: 0.9282 - val_task_output_task3_accuracy: 0.9282 - val_task_output_task4_accuracy: 0.9282 - val_task_output_task5_accuracy: 0.9282 - val_task_output_task6_accuracy: 0.9282 - val_task_output_task7_accuracy: 0.9282 - val_task_output_task8_accuracy: 0.9282 - val_task_output_task9_accuracy: 0.9282 - val_task_output_task10_accuracy: 0.9282 - val_task_output_task11_accuracy: 0.9282 - val_task_output_task12_accuracy: 0.9282 - val_task_output_task13_accuracy: 0.9282 - val_presence_output_presence_accuracy: 0.9356\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    x=X_train_encoded,\n",
    "    y={'task_output': y_train_task, 'presence_output': y_train_presence},\n",
    "    validation_data=(X_test_encoded, {'task_output': y_test_task, 'presence_output': y_test_presence}),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12d1e8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 164s 3s/step - loss: 0.4072 - task_output_loss: 0.2118 - presence_output_loss: 0.1953 - task_output_task1_accuracy: 0.9282 - task_output_task2_accuracy: 0.9282 - task_output_task3_accuracy: 0.9282 - task_output_task4_accuracy: 0.9282 - task_output_task5_accuracy: 0.9282 - task_output_task6_accuracy: 0.9282 - task_output_task7_accuracy: 0.9282 - task_output_task8_accuracy: 0.9282 - task_output_task9_accuracy: 0.9282 - task_output_task10_accuracy: 0.9282 - task_output_task11_accuracy: 0.9282 - task_output_task12_accuracy: 0.9282 - task_output_task13_accuracy: 0.9282 - presence_output_presence_accuracy: 0.9356\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_scores = model.evaluate(\n",
    "    x=X_test_encoded,\n",
    "    y={'task_output': y_test_task, 'presence_output': y_test_presence},\n",
    "    batch_size=BATCH_SIZE,\n",
    "    verbose=1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9027aec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "590c7994",
   "metadata": {},
   "outputs": [],
   "source": [
    "#presence_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceadae1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert presence predictions to binary values using a threshold of 0.5\n",
    "#binary_presence_predictions = np.round(presence_predictions).flatten().astype(int)\n",
    "\n",
    "# Convert y_test_presence to integer type if it's not already\n",
    "#y_test_presence = y_test_presence.astype(int)\n",
    "\n",
    "# Calculate presence accuracy\n",
    "#presence_accuracy = accuracy_score(y_test_presence, binary_presence_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93760963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 152s 10s/step\n",
      "Test Loss: 0.4071577489376068\n",
      "Task Output Accuracies:\n",
      "Task1 Accuracy: 0.7644444444444445\n",
      "Task2 Accuracy: 0.8511111111111112\n",
      "Task3 Accuracy: 0.96\n",
      "Task4 Accuracy: 0.9311111111111111\n",
      "Task5 Accuracy: 0.9711111111111111\n",
      "Task6 Accuracy: 0.9511111111111111\n",
      "Task7 Accuracy: 0.9622222222222222\n",
      "Task8 Accuracy: 0.9888888888888889\n",
      "Task9 Accuracy: 0.98\n",
      "Task10 Accuracy: 0.7955555555555556\n",
      "Task11 Accuracy: 0.9533333333333334\n",
      "Task12 Accuracy: 0.9688888888888889\n",
      "Task13 Accuracy: 0.9888888888888889\n",
      "Presence Output Accuracy: 0.9355555555555556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test_encoded)\n",
    "\n",
    "# Extract task and presence predictions\n",
    "task_predictions = predictions[0]\n",
    "presence_predictions = predictions[1]\n",
    "\n",
    "# Convert task predictions to binary values\n",
    "binary_task_predictions = np.round(task_predictions)\n",
    "\n",
    "# Calculate task accuracies\n",
    "task_accuracies = []\n",
    "for i in range(13):\n",
    "    task_accuracy = accuracy_score(y_test_task[:, i], binary_task_predictions[:, i])\n",
    "    task_accuracies.append(task_accuracy)\n",
    "\n",
    "# Convert presence predictions to binary values using a threshold of 0.5\n",
    "binary_presence_predictions = np.round(presence_predictions).flatten().astype(int)\n",
    "\n",
    "# Convert y_test_presence to integer type if it's not already\n",
    "y_test_presence = y_test_presence.astype(int)\n",
    "\n",
    "# Calculate presence accuracy\n",
    "presence_accuracy = accuracy_score(y_test_presence, binary_presence_predictions)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Test Loss:\", test_scores[0])\n",
    "print(\"Task Output Accuracies:\")\n",
    "for i in range(13):\n",
    "    print(\"Task{} Accuracy: {}\".format(i+1, task_accuracies[i]))\n",
    "print(\"Presence Output Accuracy:\", presence_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "abf6fb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 141s 9s/step\n",
      "Task Output Accuracies:\n",
      "Task1 Accuracy: 0.7644444444444445\n",
      "Task2 Accuracy: 0.8511111111111112\n",
      "Task3 Accuracy: 0.96\n",
      "Task4 Accuracy: 0.9311111111111111\n",
      "Task5 Accuracy: 0.9711111111111111\n",
      "Task6 Accuracy: 0.9511111111111111\n",
      "Task7 Accuracy: 0.9622222222222222\n",
      "Task8 Accuracy: 0.9888888888888889\n",
      "Task9 Accuracy: 0.98\n",
      "Task10 Accuracy: 0.7955555555555556\n",
      "Task11 Accuracy: 0.9533333333333334\n",
      "Task12 Accuracy: 0.9688888888888889\n",
      "Task13 Accuracy: 0.9888888888888889\n",
      "Presence Output Accuracy: 0.9355555555555556\n",
      "Task Output Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Task1       0.00      0.00      0.00       106\n",
      "       Task2       0.00      0.00      0.00        67\n",
      "       Task3       0.00      0.00      0.00        18\n",
      "       Task4       0.86      0.17      0.28        36\n",
      "       Task5       0.00      0.00      0.00        13\n",
      "       Task6       0.00      0.00      0.00        22\n",
      "       Task7       0.00      0.00      0.00        17\n",
      "       Task8       0.00      0.00      0.00         5\n",
      "       Task9       0.00      0.00      0.00         9\n",
      "      Task10       0.00      0.00      0.00        92\n",
      "      Task11       0.00      0.00      0.00        21\n",
      "      Task12       0.00      0.00      0.00        14\n",
      "      Task13       0.00      0.00      0.00         5\n",
      "\n",
      "   micro avg       0.86      0.01      0.03       425\n",
      "   macro avg       0.07      0.01      0.02       425\n",
      "weighted avg       0.07      0.01      0.02       425\n",
      " samples avg       0.01      0.01      0.01       425\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\madha\\anaconda3\\ANACONDA\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\madha\\anaconda3\\ANACONDA\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\madha\\anaconda3\\ANACONDA\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test_encoded)\n",
    "\n",
    "# Extract task and presence predictions\n",
    "task_predictions = predictions[0]\n",
    "presence_predictions = predictions[1]\n",
    "\n",
    "# Convert task predictions to binary values\n",
    "binary_task_predictions = np.round(task_predictions)\n",
    "\n",
    "# Calculate task accuracies\n",
    "task_accuracies = []\n",
    "for i in range(13):\n",
    "    task_accuracy = accuracy_score(y_test_task[:, i], binary_task_predictions[:, i])\n",
    "    task_accuracies.append(task_accuracy)\n",
    "\n",
    "# Convert presence predictions to binary values using a threshold of 0.5\n",
    "binary_presence_predictions = np.round(presence_predictions).flatten().astype(int)\n",
    "\n",
    "# Convert y_test_presence to integer type if it's not already\n",
    "y_test_presence = y_test_presence.astype(int)\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "target_names = ['Task1', 'Task2', 'Task3', 'Task4', 'Task5', 'Task6', 'Task7', 'Task8', 'Task9', 'Task10', 'Task11', 'Task12','Task13']\n",
    "task_report = classification_report(y_test_task, binary_task_predictions, target_names=target_names)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Task Output Accuracies:\")\n",
    "for i in range(13):\n",
    "    print(\"Task{} Accuracy: {}\".format(i+1, task_accuracies[i]))\n",
    "print(\"Presence Output Accuracy:\", presence_accuracy)\n",
    "print(\"Task Output Metrics:\")\n",
    "print(task_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e12ba64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\madha\\anaconda3\\ANACONDA\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\madha\\anaconda3\\ANACONDA\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\madha\\anaconda3\\ANACONDA\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\madha\\anaconda3\\ANACONDA\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\madha\\anaconda3\\ANACONDA\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\madha\\anaconda3\\ANACONDA\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\madha\\anaconda3\\ANACONDA\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\madha\\anaconda3\\ANACONDA\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\madha\\anaconda3\\ANACONDA\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\madha\\anaconda3\\ANACONDA\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\madha\\anaconda3\\ANACONDA\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\madha\\anaconda3\\ANACONDA\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\madha\\anaconda3\\ANACONDA\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\madha\\anaconda3\\ANACONDA\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\madha\\anaconda3\\ANACONDA\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision per Task:\n",
      "Task 1: [0.         0.         0.         0.85714286 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Task 2: [0.         0.         0.         0.85714286 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Task 3: [0.         0.         0.         0.85714286 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Task 4: [0.         0.         0.         0.85714286 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Task 5: [0.         0.         0.         0.85714286 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Task 6: [0.         0.         0.         0.85714286 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Task 7: [0.         0.         0.         0.85714286 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Task 8: [0.         0.         0.         0.85714286 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Task 9: [0.         0.         0.         0.85714286 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Task 10: [0.         0.         0.         0.85714286 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Task 11: [0.         0.         0.         0.85714286 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Task 12: [0.         0.         0.         0.85714286 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Task 13: [0.         0.         0.         0.85714286 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Task 14: [0.         0.         0.         0.85714286 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Task 15: [0.         0.         0.         0.85714286 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall per Task:\n",
      "Task 1: [0.         0.         0.         0.16666667 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Task 2: [0.         0.         0.         0.16666667 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Task 3: [0.         0.         0.         0.16666667 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Task 4: [0.         0.         0.         0.16666667 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Task 5: [0.         0.         0.         0.16666667 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Task 6: [0.         0.         0.         0.16666667 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Task 7: [0.         0.         0.         0.16666667 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Task 8: [0.         0.         0.         0.16666667 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Task 9: [0.         0.         0.         0.16666667 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Task 10: [0.         0.         0.         0.16666667 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Task 11: [0.         0.         0.         0.16666667 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Task 12: [0.         0.         0.         0.16666667 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Task 13: [0.         0.         0.         0.16666667 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Task 14: [0.         0.         0.         0.16666667 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Task 15: [0.         0.         0.         0.16666667 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1 Score per Task:\n",
      "Task 1: [0.         0.         0.         0.27906977 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Task 2: [0.         0.         0.         0.27906977 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Task 3: [0.         0.         0.         0.27906977 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Task 4: [0.         0.         0.         0.27906977 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Task 5: [0.         0.         0.         0.27906977 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Task 6: [0.         0.         0.         0.27906977 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Task 7: [0.         0.         0.         0.27906977 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Task 8: [0.         0.         0.         0.27906977 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Task 9: [0.         0.         0.         0.27906977 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Task 10: [0.         0.         0.         0.27906977 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Task 11: [0.         0.         0.         0.27906977 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Task 12: [0.         0.         0.         0.27906977 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Task 13: [0.         0.         0.         0.27906977 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Task 14: [0.         0.         0.         0.27906977 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Task 15: [0.         0.         0.         0.27906977 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculating metrics - precision, recall, and F1 score for each task\n",
    "precision = []\n",
    "recall = []\n",
    "f1_measure = []\n",
    "\n",
    "for i in range(1, 16):  # Iterate from 1 to 14\n",
    "    task_precision = precision_score(y_test_task, np.round(task_predictions), average=None)\n",
    "    task_recall = recall_score(y_test_task, np.round(task_predictions), average=None)\n",
    "    task_f1 = f1_score(y_test_task, np.round(task_predictions), average=None)\n",
    "    \n",
    "    precision.append(task_precision)\n",
    "    recall.append(task_recall)\n",
    "    f1_measure.append(task_f1)\n",
    "\n",
    "# Print precision, recall, and F1 score for each task\n",
    "print('Precision per Task:')\n",
    "for i, p in enumerate(precision):\n",
    "    print(f'Task {i+1}: {p}')\n",
    "    \n",
    "print('Recall per Task:')\n",
    "for i, r in enumerate(recall):\n",
    "    print(f'Task {i+1}: {r}')\n",
    "    \n",
    "print('F1 Score per Task:')\n",
    "for i, f in enumerate(f1_measure):\n",
    "    print(f'Task {i+1}: {f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d6b30ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task Output Metrics:\n",
      "Task1 Precision: 0.0\n",
      "Task1 Recall: 0.0\n",
      "Task1 F1-score: 0.0\n",
      "Task2 Precision: 0.0\n",
      "Task2 Recall: 0.0\n",
      "Task2 F1-score: 0.0\n",
      "Task3 Precision: 0.0\n",
      "Task3 Recall: 0.0\n",
      "Task3 F1-score: 0.0\n",
      "Task4 Precision: 0.8571428571428571\n",
      "Task4 Recall: 0.16666666666666666\n",
      "Task4 F1-score: 0.27906976744186046\n",
      "Task5 Precision: 0.0\n",
      "Task5 Recall: 0.0\n",
      "Task5 F1-score: 0.0\n",
      "Task6 Precision: 0.0\n",
      "Task6 Recall: 0.0\n",
      "Task6 F1-score: 0.0\n",
      "Task7 Precision: 0.0\n",
      "Task7 Recall: 0.0\n",
      "Task7 F1-score: 0.0\n",
      "Task8 Precision: 0.0\n",
      "Task8 Recall: 0.0\n",
      "Task8 F1-score: 0.0\n",
      "Task9 Precision: 0.0\n",
      "Task9 Recall: 0.0\n",
      "Task9 F1-score: 0.0\n",
      "Task10 Precision: 0.0\n",
      "Task10 Recall: 0.0\n",
      "Task10 F1-score: 0.0\n",
      "Task11 Precision: 0.0\n",
      "Task11 Recall: 0.0\n",
      "Task11 F1-score: 0.0\n",
      "Task12 Precision: 0.0\n",
      "Task12 Recall: 0.0\n",
      "Task12 F1-score: 0.0\n",
      "Task13 Precision: 0.0\n",
      "Task13 Recall: 0.0\n",
      "Task13 F1-score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\madha\\anaconda3\\ANACONDA\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "task_precisions, task_recalls, task_f1_scores, _ = precision_recall_fscore_support(\n",
    "    y_test_task, binary_task_predictions, average=None)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Task Output Metrics:\")\n",
    "for i, task_name in enumerate(target_names):\n",
    "    print(\"Task{} Precision: {}\".format(i+1, task_precisions[i]))\n",
    "    print(\"Task{} Recall: {}\".format(i+1, task_recalls[i]))\n",
    "    print(\"Task{} F1-score: {}\".format(i+1, task_f1_scores[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d323f71a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
